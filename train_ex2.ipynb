{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9732,"status":"ok","timestamp":1727691718305,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"D3wbHkXKc08T","outputId":"b16ad545-497d-4dfe-c7e4-e0a2e9b663d0"},"outputs":[],"source":["#pip install torch torchvision transformers faiss-cpu\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6624,"status":"ok","timestamp":1727691554057,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"hCAGQPxgb9J5"},"outputs":[],"source":["import os\n","import json\n","import torch\n","from torchvision import transforms\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":441,"status":"ok","timestamp":1727691765729,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"ykFqNXWJb9J6"},"outputs":[],"source":["# Define your custom dataset\n","class AnimalDataset(Dataset):\n","    def __init__(self, json_file, transform=None):\n","        with open(json_file) as f:\n","            self.data = json.load(f)[\"images\"]\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data[idx][\"file\"]\n","        image = Image.open(img_path).convert(\"RGB\")\n","        label = self.data[idx][\"label\"]\n","        breed = self.data[idx].get(\"product\", None)\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label, breed"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1727691766256,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"gTHAR3qgb9J7"},"outputs":[],"source":["# Define your transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# Load your dataset\n","dataset = AnimalDataset('datasets/data_local.json', transform)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1727691770032,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"lFBsS6-rb9J7"},"outputs":[],"source":["from transformers import AutoFeatureExtractor, AutoModel\n","#from datasets import load_dataset, concatenate_datasets, load_from_disk\n","from PIL import Image\n","import numpy as np"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1727691770033,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"1WhtkaOQb9J8","outputId":"31255dcc-8714-42b3-9e7e-1917f8e26d13"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\ravik\\Ravi\\Projects\\Gold_ImageSimilarity\\enve\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n","  warnings.warn(\n","Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model_ckpt = \"google/vit-base-patch16-224\"\n","\n","extractor = AutoFeatureExtractor.from_pretrained(model_ckpt)\n","model = AutoModel.from_pretrained(model_ckpt)\n","\n","hidden_dim = model.config.hidden_size"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1727691770033,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"C301awfXb9J9"},"outputs":[],"source":["import torch.nn as nn\n","\n","class Classifier(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(Classifier, self).__init__()\n","        self.fc = nn.Linear(input_dim, num_classes)\n","\n","    def forward(self, x):\n","        return self.fc(x)\n","\n","# Example for two classes (cat and dog)\n","num_classes = 2  # Change to number of breeds if needed\n","classifier = Classifier(768, num_classes)  # ViT base outputs 768-dim embeddings"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":24142,"status":"ok","timestamp":1727691794167,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"I5Hq_LmQb9J9"},"outputs":[],"source":["import faiss\n","import numpy as np\n","\n","# Prepare to store embeddings\n","embeddings = []\n","labels = []\n","\n","# Extract embeddings\n","with torch.no_grad():\n","    for images, label, breed in dataloader:\n","        outputs = model(images).last_hidden_state[:, 0, :]  # Get the [CLS] token output\n","        embeddings.append(outputs.numpy())\n","        labels.extend(label)\n","\n","# Convert to numpy arrays\n","embeddings = np.vstack(embeddings).astype('float32')\n","labels = np.array(labels)\n","\n","# Create a FAISS index\n","index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance index\n","index.add(embeddings)  # Add embeddings to the index\n","\n","\n","# Save the index to local storage\n","faiss.write_index(index, \"faiss_index.index\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1727691973855,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"zCdL9gW_dayp","outputId":"75cc4f7d-c2d9-4505-9de8-a28c2b21a2a2"},"outputs":[{"data":{"text/plain":["{'file': 'C:\\\\Users\\\\ravik\\\\Ravi\\\\Projects\\\\Gold_ImageSimilarity\\\\datasets\\\\Kasumalai\\\\Lakshmi Necklace\\\\1.png',\n"," 'label': 'Kasumalai',\n"," 'product': 'Lakshmi Necklace'}"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Create a mapping of index to (label, breed)\n","file_mapping = {\n","    i: {\n","        \"file\": img_info[\"file\"],\n","        \"label\": img_info[\"label\"],\n","        \"product\": img_info.get(\"product\", \"N/A\")  # Use \"N/A\" if breed is not available\n","    }\n","    for i, img_info in enumerate(dataset.data)\n","}\n","\n","file_mapping[0]"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":404,"status":"ok","timestamp":1727692000347,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"ACCtS2g_b9J9"},"outputs":[],"source":["def predict(image_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image = transform(image).unsqueeze(0)  # Add batch dimension\n","\n","    _k=5\n","\n","    with torch.no_grad():\n","        output = model(image).last_hidden_state[:, 0, :].numpy()\n","\n","    # Search in the FAISS index\n","    D, I = index.search(output.astype('float32'), k=_k)  # Get top 5 similar images\n","    print(\"Distances: \", D)\n","\n","    # Define a threshold and calculate matching percentage\n","    threshold = 0.5  # Example threshold\n","    matches = (D < threshold).astype(int)  # 1 for match, 0 for no match\n","\n","    print(matches)\n","\n","    # Calculate the percentage of matches\n","    #matching_percentage = np.mean(matches) * 100  # Mean across all queries\n","    \n","\n","    # Calculate percentage of matches for each index\n","    matching_percentages = (matches.sum(axis=1) / _k) * 100  # Mean matches per query\n","    print(f\"Matching Percentage: {matching_percentages:.2f}%\")\n","    \n","    print(I)\n","    # Retrieve metadata based on indices\n","    predicted_metadata = [\n","        {\n","            \"file\": file_mapping[idx][\"file\"],\n","            \"label\": file_mapping[idx][\"label\"],\n","            \"product\": file_mapping[idx][\"product\"],\n","            \"Matching_Percent\": (matches.sum(axis=1) / _k) * 100\n","\n","        }\n","        for idx in I[0] # Get the first query results\n","    ]\n","\n","    return predicted_metadata"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1636,"status":"ok","timestamp":1727692029717,"user":{"displayName":"Ravi Hattikal","userId":"04135262327522039199"},"user_tz":-330},"id":"Y-4hqgLQb9J-","outputId":"be9c8033-8387-4eb5-be92-45d1234d0d4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Distances:  [[  0.      443.49084 485.0205  498.6761  513.2071 ]]\n","[[1 0 0 0 0]]\n","Matching Percentage: 20.00%\n","[[17  7  3 10 22]]\n","File: C:\\Users\\ravik\\Ravi\\Projects\\Gold_ImageSimilarity\\datasets\\Bracelets\\Chain\\3.jpg, Label: Bracelets, Product: Chain\n","File: C:\\Users\\ravik\\Ravi\\Projects\\Gold_ImageSimilarity\\datasets\\Bracelets\\Cuff\\1.jpg, Label: Bracelets, Product: Cuff\n","File: C:\\Users\\ravik\\Ravi\\Projects\\Gold_ImageSimilarity\\datasets\\Kasumalai\\Lakshmi Necklace\\4.png, Label: Kasumalai, Product: Lakshmi Necklace\n","File: C:\\Users\\ravik\\Ravi\\Projects\\Gold_ImageSimilarity\\datasets\\Bracelets\\Cuff\\3.jpg, Label: Bracelets, Product: Cuff\n","File: C:\\Users\\ravik\\Ravi\\Projects\\Gold_ImageSimilarity\\datasets\\Rings\\Casuals\\1.jpg, Label: Rings, Product: Casuals\n"]}],"source":["# Example prediction\n","predicted_results = predict(r'C:\\Users\\ravik\\Ravi\\Projects\\Gold_ImageSimilarity\\datasets\\Rings\\Casuals\\2.jpg')\n","for result in predicted_results:\n","    print(f\"File: {result['file']}, Label: {result['label']}, Product: {result['product']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbGJ9NINd_FR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":0}
